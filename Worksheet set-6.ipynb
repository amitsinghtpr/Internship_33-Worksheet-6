{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb613718",
   "metadata": {},
   "source": [
    "###                            Assignment-6                         \n",
    "####                                                                                  Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10c98a1",
   "metadata": {},
   "source": [
    "**Q1 to Q5, only one option is correct, Choose the correct option:**\n",
    "\n",
    "1. In which of the following you can say that the model is overfitting?\n",
    "\n",
    "A) High R-squared value for train-set and High R-squared value for test-set.\n",
    "\n",
    "B) Low R-squared value for train-set and High R-squared value for test-set.\n",
    "\n",
    "C) High R-squared value for train-set and Low R-squared value for test-set.\n",
    "\n",
    "D) None of the above\n",
    "\n",
    "Ans: C) High R-squared value for train-set and Low R-squared value for test-set.\n",
    "\n",
    "2. Which among the following is a disadvantage of decision trees?\n",
    "\n",
    " A) Decision trees are prone to outliers.\n",
    " \n",
    "B) Decision trees are highly prone to overfitting.\n",
    "\n",
    "C) Decision trees are not easy to interpret\n",
    "\n",
    "D) None of the above.\n",
    "\n",
    "Ans:B) Decision trees are highly prone to overfitting.\n",
    "\n",
    "3. Which of the following is an ensemble technique?\n",
    "\n",
    " A) SVM\n",
    " \n",
    " B) Logistic Regression\n",
    " \n",
    "C) Random Forest \n",
    "\n",
    "D) Decision tree\n",
    "\n",
    "Ans:C) Random Forest \n",
    "\n",
    "4. Suppose you are building a classification model for detection of a fatal disease where detection of \n",
    "the disease is most important. In this case which of the following metrics you would focus on?\n",
    "A) Accuracy B) Sensitivity\n",
    "C) Precision D) None of the above.\n",
    "\n",
    "Ans: B) Sensitivity\n",
    "\n",
    "5. The value of AUC (Area under Curve) value for ROC curve of model A is 0.70 and of model B is \n",
    "0.85. Which of these two models is doing better job in classification?\n",
    "A) Model A B) Model B\n",
    "C) both are performing equal D) Data Insufficient\n",
    "\n",
    "Ans:B) Model B\n",
    "\n",
    "**In Q6 to Q9, more than one options are correct, Choose all the correct options:**\n",
    "\n",
    "6. Which of the following are the regularization technique in Linear Regression?? \n",
    "A) Ridge B) R-squared\n",
    " C) MSE D) Lasso\n",
    "\n",
    "Ans:A) Ridge,D) Lasso\n",
    "\n",
    "7. Which of the following is not an example of boosting technique?\n",
    " A) Adaboost B) Decision Tree\n",
    "C) Random Forest D) Xgboost.\n",
    "\n",
    "Ans: C) Random Forest\n",
    "\n",
    "8. Which of the techniques are used for regularization of Decision Trees? \n",
    "A) Pruning B) L2 regularization\n",
    "C) Restricting the max depth of the tree D) All of the above\n",
    "\n",
    "Ans:D) All of the above\n",
    "\n",
    "9. Which of the following statements is true regarding the Adaboost technique?\n",
    "A) We initialize the probabilities of the distribution as 1/n, where n is the number of data-points\n",
    "B) A tree in the ensemble focuses more on the data points on which the previous tree was not \n",
    "performing well\n",
    "C) It is example of bagging technique\n",
    "D) N\n",
    "\n",
    "Ans:B) A tree in the ensemble focuses more on the data points on which the previous tree was not \n",
    "performing well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed19bdc8",
   "metadata": {},
   "source": [
    "**Q10 to Q15 are subjective answer type questions, Answer them briefly.\n",
    "\n",
    "10. Explain how does the adjusted R-squared penalize the presence of unnecessary predictors in the\n",
    "model?\n",
    "\n",
    "Ans:The adjusted R-squared formula penalizes the presence of unnecessary predictors in the model by subtracting a term from the R-squared. This term increases as the number of predictors increases relative to the sample size. The adjusted R-squared value will only increase if the additional predictor significantly improves the model's predictive power beyond what would be expected by chance.In summary, the adjusted R-squared is a modified version of R-squared that takes into account the number of predictors in the model. It helps to avoid overfitting and provides a more accurate measure of the model's generalization performance.\n",
    "\n",
    "11. Differentiate between Ridge and Lasso Regression.\n",
    "\n",
    "Ans:Ridge regression: Adds a penalty term equal to the square of the coefficients. It shrinks the coefficients of all predictors towards zero, but does not eliminate any predictors. It is useful when all predictors are potentially useful, but some may have a small effect. It generally produces less sparse models.\n",
    "\n",
    "Lasso regression: Adds a penalty term equal to the absolute value of the coefficients. It can eliminate some predictors by setting their coefficients to zero, effectively removing them from the model. It is useful when the number of predictors is high, and some are less important or irrelevant. It can produce very sparse models.\n",
    "\n",
    "In short we can say, Ridge regression shrinks all the coefficients towards zero, while Lasso regression can eliminate some of the coefficients entirely. The choice of which technique to use depends on the problem at hand and the characteristics of the predictors.\n",
    "\n",
    "12. What is VIF? What is the suitable value of a VIF for a feature to be included in a regression \n",
    "modelling?\n",
    "\n",
    "Ans:VIF stands for Variance Inflation Factor, and it is a measure of the degree of multicollinearity (correlation) among the predictor variables in a linear regression model. Specifically, it measures the extent to which the variance of the estimated regression coefficient is increased due to multicollinearity among the predictors.\n",
    "\n",
    "The VIF for a predictor variable is calculated as the ratio of the variance of its estimated coefficient in a model that includes all the predictor variables to the variance of its estimated coefficient in a model that excludes that particular predictor variable. The VIF for a predictor variable ranges from 1 to infinity, with a VIF of 1 indicating no multicollinearity and a VIF greater than 1 indicating some degree of multicollinearity.\n",
    "\n",
    "The suitable value of VIF for a feature to be included in a regression model depends on the degree of multicollinearity that is acceptable for the problem at hand. As a general rule of thumb, a VIF value of 1 to 2 is considered low and indicates little to no multicollinearity, while a VIF value of 5 to 10 or higher indicates high multicollinearity and suggests that the variable may need to be removed from the model.\n",
    "\n",
    "However, the suitable value of VIF also depends on the context of the problem and the complexity of the model. In some cases, a higher VIF may be acceptable if the variable is essential to the model and removing it would result in a loss of important information. On the other hand, in other cases, a lower VIF may be required if the model needs to be simpler and more interpretable. Ultimately, the decision of what VIF value to use should be based on a careful consideration of the problem at hand and the goals of the analysis.\n",
    "\n",
    "13. Why do we need to scale the data before feeding it to the train the model?\n",
    "\n",
    "Ans:Scaling the data before feeding it to a machine learning model can be important for several reasons:\n",
    "\n",
    "Different scales: When the features of the dataset are measured in different units, or have different ranges of values, the scale of each feature can impact the way the model interprets the importance of each feature. For example, if one feature has values that range from 0 to 1 and another feature has values that range from 0 to 100, the model may incorrectly assign more importance to the feature with the larger range of values. Scaling the data puts all the features on a similar scale, which can improve the accuracy and stability of the model.\n",
    "\n",
    "Gradient-based algorithms: Many machine learning algorithms rely on gradient-based optimization techniques to minimize a loss function and find the optimal set of model parameters. If the data is not scaled, the gradients can be different for each feature and this can cause the optimization process to take longer or get stuck in local optima. Scaling the data can speed up the optimization process and improve the overall performance of the model.\n",
    "\n",
    "Regularization: Some regularization techniques, such as Ridge and Lasso regression, penalize large coefficients in the model. If the data is not scaled, features with larger scales will tend to have larger coefficients, even if they are not more important. Scaling the data ensures that all features are equally penalized for having large coefficients, which can help to prevent overfitting.\n",
    "\n",
    "Overall, scaling the data can improve the performance, stability, and interpretability of machine learning models. Common methods of scaling data include standardization (subtracting the mean and dividing by the standard deviation), min-max scaling (scaling the values to a specific range, such as 0 to 1), and normalization (scaling the values to have unit norm).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "14. What are the different metrics which are used to check the goodness of fit in linear regression?\n",
    "\n",
    "Ans:In linear regression, there are several metrics that can be used to check the goodness of fit of the model. Some of the commonly used metrics are:\n",
    "\n",
    "R-squared: R-squared is a measure of how well the linear regression model fits the data. It represents the proportion of the variance in the dependent variable that is explained by the independent variables. R-squared values range from 0 to 1, with higher values indicating a better fit.\n",
    "\n",
    "Mean squared error (MSE): MSE measures the average squared difference between the predicted and actual values of the dependent variable. It gives an indication of the average magnitude of the errors in the model predictions.\n",
    "\n",
    "Root mean squared error (RMSE): RMSE is the square root of the MSE and represents the average magnitude of the errors in the same units as the dependent variable.\n",
    "\n",
    "Mean absolute error (MAE): MAE is the average absolute difference between the predicted and actual values of the dependent variable. It gives an indication of the average magnitude of the errors in the model predictions.\n",
    "\n",
    "Residual plots: Residual plots can be used to visually check the goodness of fit of the model. A residual plot shows the difference between the predicted and actual values of the dependent variable for each observation, plotted against the independent variable. The plot should not show any clear patterns, which would indicate that the model is not capturing all of the relevant information in the data.\n",
    "Overall, these metrics can be used to evaluate the performance of a linear regression model and to compare the performance of different models. However, it's important to keep in mind that no single metric can provide a complete picture of the goodness of fit, and it's often useful to use a combination of metrics and visual inspection to evaluate the model.\n",
    "\n",
    "15. From the following confusion matrix calculate sensitivity, specificity, precision, recall and accuracy.\n",
    "\n",
    " Actual       /Predicted     |True | False\n",
    "\n",
    "     True                 |1000 | 50\n",
    "\n",
    "     False                |250  | 1200\n",
    "\n",
    "Ans:\n",
    "Sensitivity = TP / (TP + FN) = 1000 / (1000 + 250) = 0.8\n",
    "\n",
    "Specificity = TN / (TN + FP) = 1200 / (1200 + 50) = 0.96\n",
    "\n",
    "Precision = TP / (TP + FP) = 1000 / (1000 + 50) = 0.95\n",
    "\n",
    "Recall = TP / (TP + FN) = 1000 / (1000 + 250) = 0.8\n",
    "\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN) = (1000 + 1200) / (1000 + 1200 + 50 + 250) = 0.88"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5443eeff",
   "metadata": {},
   "source": [
    "### ASSIGNMENT = 6\n",
    "\n",
    "\n",
    "### WORKSHEET 6             \n",
    " \n",
    "**SQL**\n",
    "\n",
    "**Q1 and Q2 have one or more correct answer. Choose all the correct option to answer your question.**\n",
    "\n",
    "\n",
    "1. Which of the following are TCL commands?\n",
    "\n",
    "A. Commit\n",
    "B. Select\n",
    "C. Rollback\n",
    "D. Savepoint\n",
    "\n",
    "Ans: A. Commit,C. Rollback,D. Savepoint\n",
    "\n",
    "2. Which of the following are DDL commands?\n",
    "\n",
    "A. Create\n",
    "B. Select\n",
    "C. Drop\n",
    "D. Alter\n",
    "\n",
    "Ans:A. Create,C. Drop,D. Alter\n",
    "\n",
    " Q3 to Q10 have only one correct answer. Choose the correct option to answer your question.\n",
    " \n",
    "3. Which of the following is a legal expression in SQL? \n",
    "\n",
    "A. SELECT NULL FROM SALES;\n",
    "B. SELECT NAME FROM SALES;\n",
    "C. SELECT * FROM SALES WHEN PRICE = NULL;\n",
    "D. SELECT # FROM SALES;\n",
    "\n",
    "Ans: B.SELECT NAME FROM SALES;\n",
    "\n",
    "4. DCL provides commands to perform actions like\u0002\n",
    "\n",
    "A. Change the structure of Tables\n",
    "B. Insert, Update or Delete Records and Values\n",
    "C. Authorizing Access and other control over Database\n",
    "D. None of the above\n",
    "\n",
    "Ans:C. Authorizing Access and other control over Database\n",
    "\n",
    "5. Which of the following should be enclosed in double quotes?\n",
    "A. Dates\n",
    "B. Column Alias\n",
    "C. String\n",
    "D. All of the mentioned\n",
    "\n",
    "Ans:C. String\n",
    "\n",
    "6. Which of the following command makes the updates performed by the transaction permanent in the database?\n",
    "A. ROLLBACK\n",
    "B. COMMIT\n",
    "C. TRUNCATE\n",
    "D. DELETE\n",
    "\n",
    "Ans:B. COMMIT\n",
    "\n",
    "7. A subquery in an SQL Select statement is enclosed in:\n",
    "\n",
    "A. Parenthesis - (...).\n",
    "B. brackets - [...].\n",
    "C. CAPITAL LETTERS.\n",
    "D. braces - {...}.\n",
    "\n",
    "Ans:A. Parenthesis - (...).\n",
    "\n",
    "8. The result of a SQL SELECT statement is a :-\n",
    "\n",
    "A. FILE\n",
    "B. REPORT\n",
    "C. TABLE\n",
    "D. FORM \n",
    "ASSIGNMENT\n",
    "\n",
    "Ans:C. TABLE\n",
    "\n",
    "9. Which of the following do you need to consider when you make a table in a SQL?\n",
    "\n",
    "A. Data types\n",
    "B. Primary keys\n",
    "C. Default values\n",
    "D. All of the mentioned\n",
    "\n",
    "Ans:D. All of the mentioned\n",
    "\n",
    "10. If you donâ€™t specify ASC and DESC after a SQL ORDER BY clause, the following is used by___?\n",
    "\n",
    "A. ASC\n",
    "B. DESC\n",
    "C. There is no default value\n",
    "D. None of the mentioned\n",
    "\n",
    "Ans:A. ASC\n",
    "\n",
    "**Q11 to Q15 are subjective answer type questions, Answer them briefly.**\n",
    "\n",
    "11. What is denormalization?\n",
    "\n",
    "Ans:Denormalization is the process of deliberately adding redundant information to one or more tables in a database to improve query performance by avoiding costly joins. It involves transforming a highly normalized database into one that is less normalized or less structured, often by adding redundant data to one or more tables.\n",
    "\n",
    "In a highly normalized database, data is organized into multiple tables and each table has a specific purpose, with each column containing unique information. However, sometimes it can be useful to combine multiple tables or duplicate some of the data to optimize queries and improve performance.\n",
    "\n",
    "For example, if a database is highly normalized and consists of multiple tables, performing complex queries across those tables may be resource-intensive and slow. In such cases, denormalizing the tables and combining them into a single table can help speed up queries by eliminating the need for joins. However, denormalization can also introduce data redundancy, which can lead to data inconsistencies and higher storage requirements. Therefore, it should be used judiciously and only when necessary for specific use cases.\n",
    "\n",
    "12. What is a database cursor?\n",
    "\n",
    "Ans:In database management, a cursor is a control structure used by database programs to allow the traversal of records in a database. It allows the program to fetch a specific record or set of records, move forward or backward through the database, and update or delete records as needed. Essentially, a cursor is a pointer to the current row in a result set returned by a SQL query. Cursors are commonly used in database applications to process large sets of data, and are particularly useful when dealing with complex queries or when updates need to be made to a specific subset of records.\n",
    "\n",
    "13. What are the different types of the queries?\n",
    "\n",
    "Ans:In the context of databases, there are several types of queries that can be used to retrieve data from a database. Some of the most common types of queries include:\n",
    "\n",
    "Select Query: This type of query is used to retrieve data from one or more tables in the database.\n",
    "\n",
    "Insert Query: This type of query is used to add new data to a table in the database.\n",
    "\n",
    "Update Query: This type of query is used to modify existing data in a table in the database.\n",
    "\n",
    "Delete Query: This type of query is used to remove data from a table in the database.\n",
    "\n",
    "Join Query: This type of query is used to combine data from multiple tables in the database based on a common column.\n",
    "\n",
    "Subquery: This type of query is used to retrieve data from one or more tables in the database by using the results of another query as a condition.\n",
    "\n",
    "Aggregate Query: This type of query is used to calculate and retrieve summary information from a table in the database, such as the average or sum of a column.\n",
    "\n",
    "Stored Procedure: This type of query is a pre-compiled and stored SQL query that can be called multiple times by applications or other queries, which can help improve performance and reduce complexity.\n",
    "\n",
    "14. Define constraint?\n",
    "\n",
    "Ans:A constraint is a rule that restricts the values or properties of a column or a set of columns in a table. Constraints ensure the integrity of the data in a database by imposing limitations on the data that can be stored in the table.\n",
    "\n",
    "There are several types of constraints that can be applied to a table, including:\n",
    "\n",
    "NOT NULL constraint: ensures that a column does not contain null values.\n",
    "UNIQUE constraint: ensures that a column or a combination of columns in a table contain unique values.\n",
    "PRIMARY KEY constraint: identifies a column or a combination of columns as the unique identifier for a row in a table.\n",
    "FOREIGN KEY constraint: establishes a relationship between two tables by enforcing referential integrity.\n",
    "CHECK constraint: restricts the values that can be inserted into a column based on a condition.\n",
    "DEFAULT constraint: specifies a default value for a column when a value is not explicitly provided during an insert operation.\n",
    "Constraints help to maintain the quality and consistency of the data in a database and prevent data inconsistencies or errors.\n",
    "\n",
    "15. What is auto increment? \n",
    "\n",
    "Ans:Auto increment is a feature in many database management systems that allows a field to be automatically incremented with a new value each time a new record is inserted into a table. This is typically used to automatically assign unique identifiers to records. For example, a database table for customer orders may have an auto-incremented OrderID field, so that each new order is assigned a unique, sequentially increasing ID number. The auto-increment feature is often used as a primary key for a table, allowing records to be uniquely identified and easily accessed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c07ac",
   "metadata": {},
   "source": [
    "## WORKSHEET\n",
    "\n",
    "## STATISTICS \n",
    "\n",
    "**WORKSHEET- 6**\n",
    "\n",
    "Q1 to Q9 have only one correct answer. Choose the correct option to answer your question.\n",
    "\n",
    "1. Which of the following can be considered as random variable?\n",
    "\n",
    "a) The outcome from the roll of a die\n",
    "b) The outcome of flip of a coin\n",
    "c) The outcome of exam\n",
    "d) All of the mentioned\n",
    "\n",
    "Ans:d) All of the mentioned\n",
    "\n",
    "\n",
    "2. Which of the following random variable that take on only a countable number of possibilities?\n",
    "\n",
    "a) Discrete\n",
    "b) Non Discrete\n",
    "c) Continuous\n",
    "d) All of the mentioned\n",
    "\n",
    "Ans:a) Discrete\n",
    "\n",
    "3. Which of the following function is associated with a continuous random variable?\n",
    "\n",
    "a) pdf\n",
    "b) pmv\n",
    "c) pmf\n",
    "d) all of the mentioned\n",
    "\n",
    "Ans:a) pdf\n",
    "\n",
    "4. The expected value or _______ of a random variable is the center of its distribution.\n",
    "\n",
    "a) mode\n",
    "b) median\n",
    "c) mean\n",
    "d) bayesian inference\n",
    "\n",
    "Ans:c) mean\n",
    "\n",
    "5. Which of the following of a random variable is not a measure of spread?\n",
    "\n",
    "a) variance\n",
    "b) standard deviation\n",
    "c) empirical mean\n",
    "d) all of the mentioned\n",
    "\n",
    "Ans:c) empirical mean\n",
    "\n",
    "6. The _________ of the Chi-squared distribution is twice the degrees of freedom.\n",
    "\n",
    "a) variance\n",
    "b) standard deviation\n",
    "c) mode\n",
    "d) none of the mentioned\n",
    "\n",
    "Ans:a) variance\n",
    "\n",
    "7. The beta distribution is the default prior for parameters between ____________\n",
    "\n",
    "a) 0 and 10\n",
    "b) 1 and 2\n",
    "c) 0 and 1\n",
    "d) None of the mentioned\n",
    "\n",
    "Ans:c) 0 and 1\n",
    "\n",
    "8. Which of the following tool is used for constructing confidence intervals and calculating standard errors for \n",
    "difficult statistics?\n",
    "\n",
    "a) baggyer\n",
    "b) bootstrap\n",
    "c) jacknife\n",
    "d) none of the mentioned\n",
    "\n",
    "Ans:b) bootstrap\n",
    "\n",
    "9. Data that summarize all observations in a category are called __________ data.\n",
    "\n",
    "a) frequency\n",
    "b) summarized\n",
    "c) raw\n",
    "d) none of the mentioned\n",
    "\n",
    "Ans: b) summarized\n",
    "\n",
    "**Q10and Q15 are subjective answer type questions, Answer them in your own words briefly.**\n",
    "\n",
    "10. What is the difference between a boxplot and histogram?\n",
    "\n",
    "Ans:A histogram is a graphical representation of the distribution of a continuous variable. It is a bar graph-like representation of the data that separates it into different ranges or bins. The height of each bar represents the number of data points that fall within each bin.\n",
    "\n",
    "A boxplot, on the other hand, is a graphical representation of the distribution of a continuous variable based on five summary statistics: minimum, first quartile, median, third quartile, and maximum. It is a box-and-whisker diagram that gives a visual indication of the data's median, the interquartile range (IQR), and the data's variability.\n",
    "The main difference between a boxplot and a histogram is that a histogram shows the distribution of the data using the frequency of data points within certain intervals, while a boxplot shows the distribution of the data based on summary statistics.\n",
    "\n",
    "11. How to select metrics?\n",
    "\n",
    "Ans:Selecting appropriate metrics is an important step in any machine learning or data analysis project. Here are some general guidelines to help you select the right metrics:\n",
    "\n",
    "Start with the project objective: The metrics you choose should be aligned with the project objective. For example, if your objective is to maximize accuracy, then accuracy is the most appropriate metric.\n",
    "\n",
    "Consider the business context: You should choose metrics that are relevant to the business context of your project. For example, if you are working on a fraud detection system, then precision may be more important than recall.\n",
    "\n",
    "Understand the limitations of the data: Sometimes the data may have certain limitations that make it difficult to use certain metrics. For example, if the data is imbalanced, then accuracy may not be a suitable metric.\n",
    "\n",
    "Evaluate multiple metrics: It is often useful to evaluate multiple metrics to get a more complete picture of model performance. For example, in addition to accuracy, you may want to evaluate precision, recall, and F1 score.\n",
    "\n",
    "Consider the tradeoffs: Some metrics may be in conflict with each other, so you need to consider the tradeoffs. For example, increasing recall may decrease precision, so you need to find a balance that works for your project.\n",
    "\n",
    "Choose metrics that are easy to interpret: Finally, it is important to choose metrics that are easy to interpret and communicate to stakeholders. A metric like accuracy is easy to understand and explain, whereas more complex metrics may be difficult to explain to non-technical stakeholders.\n",
    "\n",
    "12. How do you assess the statistical significance of an insight?\n",
    "\n",
    "Ans:To assess the statistical significance of an insight, it is important to use appropriate statistical tests and methods. This involves setting up a hypothesis, collecting and analyzing data, and using statistical tests to determine if the results are significant or not.\n",
    "\n",
    "The level of significance is typically set at a p-value of 0.05 or lower, which means that there is a 5% or lower chance that the results are due to chance. It is also important to consider the effect size, which measures the practical significance of the result.\n",
    "\n",
    "Additionally, it is important to consider the context and potential confounding factors that could impact the results. This includes considering the study design, sample size, and any potential biases or limitations.\n",
    "\n",
    "Overall, assessing the statistical significance of an insight requires careful planning and analysis to ensure that the results are reliable and meaningful.\n",
    "\n",
    "13. Give examples of data that doesnot have a Gaussian distribution, nor log-normal.\n",
    "\n",
    "Ans:There are many types of data that do not have a Gaussian or log-normal distribution. Here are a few examples:\n",
    "\n",
    "Power law distributed data: Power law distributions are characterized by a small number of very large events or values and a large number of very small events or values. Examples include the distribution of the sizes of earthquakes or the popularity of websites.\n",
    "\n",
    "Exponential distributed data: Exponential distributions are characterized by a rapid decay in the frequency of events as the value of the event increases. Examples include the time between successive requests to a website or the time between the failure of components in a system.\n",
    "\n",
    "Bimodal distributed data: Bimodal distributions have two peaks in the distribution, indicating two distinct modes or clusters of data. Examples include the height of males and females in a population or the distribution of income in a population.\n",
    "\n",
    "Poisson distributed data: Poisson distributions are used to model the number of occurrences of an event in a fixed interval of time or space. Examples include the number of cars passing through a toll booth in an hour or the number of mutations in a DNA sequence.\n",
    "\n",
    "Uniform distributed data: Uniform distributions are characterized by all values in the distribution having an equal probability of occurring. Examples include the results of rolling a fair die or selecting a random number between 1 and 10.\n",
    "\n",
    "These are just a few examples of data that do not have a Gaussian or log-normal distribution, and there are many other types of distributions that can occur in different contexts.\n",
    "\n",
    "14. Give an example where the median is a better measure than the mean.\n",
    "\n",
    "Ans:\n",
    "\n",
    "The median is a better measure than the mean in situations where there are extreme values or outliers that may heavily influence the mean.\n",
    "\n",
    "For example, let's say we want to determine the typical income of a group of individuals. We have the following income data: $30,000, $35,000, $40,000, $45,000, $50,000, $1,000,000.\n",
    "\n",
    "The mean income for this group is calculated by summing all the incomes and dividing by the number of individuals in the group:\n",
    "\n",
    "Mean income = (30,000 + 35,000 + 40,000 + 45,000 + 50,000 + 1,000,000) / 6 = $183,333.33\n",
    "\n",
    "However, the income of $1,000,000 is an outlier and not representative of the typical income of this group. In this case, the median income would be a better measure of the typical income because it is not affected by extreme values.\n",
    "\n",
    "The median income is calculated by arranging the incomes in order and selecting the middle value:\n",
    "\n",
    "Median income = $40,000\n",
    "\n",
    "Therefore, in this example, the median income of $40,000 is a better measure than the mean income of $183,333.33 because it is not influenced by the extreme value of $1,000,000.\n",
    "\n",
    "15. What is the Likelihood?\n",
    "\n",
    "Ans:In statistics, likelihood refers to the probability of observing a set of data or sample, given a particular set of model parameters. The likelihood function is the function that describes this probability, and it is often used in maximum likelihood estimation.\n",
    "\n",
    "To calculate the likelihood, we start with a statistical model that represents the underlying probability distribution of the data. This model includes one or more parameters, such as the mean or variance, that need to be estimated from the data.\n",
    "\n",
    "The likelihood function is then defined as the probability of observing the data, given the values of the model parameters. It is a function of the model parameters and the observed data, and it can be written as:\n",
    "\n",
    "Likelihood = P(data | model parameters)\n",
    "\n",
    "The likelihood function is used in maximum likelihood estimation to find the values of the model parameters that maximize the probability of observing the data. This is done by calculating the likelihood function for different values of the parameters and selecting the values that give the highest likelihood.\n",
    "\n",
    "It is important to note that the likelihood function is not a probability distribution itself. It is simply a function that describes the probability of observing the data, given a particular set of model parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ddcda3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1a1c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
